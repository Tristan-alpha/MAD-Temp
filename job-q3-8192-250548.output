Starting Experiment 1: Modifying Round 2
Running Round 2, Agent 0, Temp 0
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:17<00:35, 17.62s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:34<00:17, 17.37s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:35<00:00,  9.60s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:35<00:00, 11.73s/it]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:05<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 15.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 0.5
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.21it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.76it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:09<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 1.0
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.20it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.18it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.75it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [06:22<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 46.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 45.56 MiB is free. Including non-PyTorch memory, this process has 39.44 GiB memory in use. Of the allocated memory 23.42 GiB is allocated by PyTorch, and 15.53 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 1.5
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.20it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.16it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.72it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:15<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 2.0
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.21it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.17it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.74it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:15<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 5.0
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.11it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.14it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.68it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:15<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 10.0
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.19it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.15it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.71it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:16<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
Running Round 2, Agent 0, Temp 20.0
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:00<00:01,  1.14it/s]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:01<00:00,  1.11it/s]Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  1.65it/s]
Device set to use cuda:0
  0%|          | 0/500 [00:00<?, ?it/s]

Question:  Finley went to the grocery store and bought rice, beans, and pork for use in their home. It took her 20 more minutes to cook pork than rice, while beans took half the combined cooking time of pork and rice. If it took her 30 minutes to cook rice, how long in minutes did it take to cook all the food? Make sure to state your final answer in curly brackets at the very end of your response, just like: "{final answer: 123}". 

Gathering initial opinions...
ROUND 0 : [np.float64(120.0), np.float64(120.0), np.float64(120.0)] (answer = 120)
Debating round 1...
Debating round 2...
  0%|          | 0/500 [11:10<?, ?it/s]
Traceback (most recent call last):
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 374, in <module>
    main(args)
  File "/export/home3/dazhou/debate-or-vote/src/main.py", line 272, in main
    responses = engine(messages, agent, args.num_agents, temperatures=temperatures, max_new_tokens=args.max_new_tokens)
  File "/export/home3/dazhou/debate-or-vote/src/model/model_utils.py", line 63, in engine
    outputs = agent.huggingface_model.generate(**gen_kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 2629, in generate
    result = self._sample(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/generation/utils.py", line 3613, in _sample
    outputs = model_forward(**model_inputs, return_dict=True)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 959, in wrapper
    output = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 481, in forward
    outputs: BaseModelOutputWithPast = self.model(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/utils/generic.py", line 1083, in wrapper
    outputs = func(self, *args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 405, in forward
    hidden_states = decoder_layer(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_layers.py", line 94, in __call__
    return super().__call__(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 257, in forward
    hidden_states, _ = self.self_attn(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1751, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1762, in _call_impl
    return forward_call(*args, **kwargs)
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/models/qwen3/modeling_qwen3.py", line 214, in forward
    attn_output, attn_weights = attention_interface(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/integrations/flash_attention.py", line 64, in flash_attention_forward
    attn_output = _flash_attention_forward(
  File "/export/home3/dazhou/miniconda3/envs/venv/lib/python3.10/site-packages/transformers/modeling_flash_attention_utils.py", line 672, in _flash_attention_forward
    v = value_states.reshape(-1, value_states.size(-2), value_states.size(-1))
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 22.00 MiB. GPU 0 has a total capacity of 39.49 GiB of which 13.56 MiB is free. Including non-PyTorch memory, this process has 39.47 GiB memory in use. Of the allocated memory 21.30 GiB is allocated by PyTorch, and 17.67 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
All experiments completed.
